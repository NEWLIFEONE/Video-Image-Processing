
**最近跟着老师在做图像相关项目，开发过程的问题还是要记录下来，很多问题网上都没有，需要自己摸索**

**很早之前就想写blog，但写好一篇blog确实需要花点时间所以拖到现在。现在想想确实花点时间是值得的**

**尽可能写好，但看起来更像是随笔。许多细节内容日后会慢慢添加**

**这里由于时间和知识的有限，没有自己移植内核和QT所以采用了厂商移植好的linux+QT**

* 开发板：s5pv210 cortex-A8
* 烧写的镜像：内核2.6.35+QT4.8.３
* 摄像头型号：映美精 DFK 22BUC03 USB2.0 CCD摄像头

用到的一些资料地址：


[TOC]

## 开发随笔

### 2016-12-21 制作nfs挂载的根文件系统并挂载（failed）

本来想像之前做驱动开发那样的，内核镜像用ftfp下载，用nfs挂载rootfs

看了linux+qt厂商自带的源码包，查了查buildroot和看了看mk文件（重要）内容，《x210v3 Linux平台用户手册》

好不容易弄出了文件形式的rootfs，也知道了配置kernel

配置kernel支持挂载nfs形式的rootfs。但是结果是失败的。

根据打印信息，挂载是成功了，但执行到到某一步的时候打印：
`nfs: server 192.168.1.141 not responding, still trying`

百度了一波，发现可能原因是——挂载完根文件之后执行/etc/init.d/rcS之后，ip相关配置被改变了

明天在继续，如果不行就只能用SD卡来进行文件的转移了

###2016-12-22 修改开发板ip配置，使能挂载net files

不打算去弄什么nfs挂载根文件系统了，只求能挂载nfs就好了

* ubuntu 搭建nfs：*（这里应该有一篇bog）*

在开发板运行linux下去ping ubuntu 发现ping 不同：猜测是ip配置问题

`vi /etc/network/interfaces `

设置成静态ip
```
auto eth0
iface eth0 inet static
address 192.168.1.10
netmask 255.255.255.0
gateway 192.168.1.1
```
还有一个问题：开发板运行后控制台老是会不停打印一些信息

这个printk的信息打印级别有关
```
cat /proc/sys/kernel/printk
- > 7       4       1       7
```
尝试修改成6看可不可以
```
echo 6 > /proc/sys/kernel/printk
cat /proc/sys/kernel/printk
- > 6       4       1       7
```
成功！（注：KERN_DBUG 级别8 KERN_INFO 级别7）

----------------------------------------------------------------------

### 2016-12-22 关键词：程序开机自启动 触摸屏校准（ing）

找老师梳理了一下开发流程，拿到工业摄像头

熟悉了一下rcS 知道怎么去关闭自启动程序和添加开机自启动程序的方法*（这里应该有一篇bog）*

进入/etc/init.d/ 把S99qttest把改成noS99qttest

没有执行自带程序qttest了，但是执行测试程序时qt001不能正确执行

根据提示./qt001 -qws 程序能执行了，但是触摸屏鼠标指针会漂移，就是乱跑


再看一看S99qttest
```
#!/bin/sh
#
# Start the qttest....
#

export TSLIB_TSDEVICE=/dev/input/event2
export TSLIB_TSEVENTTYPE=INPUT
export TSLIB_CONFFILE=/etc/ts.conf
export TSLIB_CALIBFILE=/etc/pointercal
export QWS_MOUSE_PROTO="Tslib:/dev/input/event2 MouseMan:/dev/input/mouse2"

case "$1" in
  start)
        echo "Starting qttest..."
        /usr/share/demo/qttest -qws &
        /usr/share/demo/hdmi_x210 &
        mkdir -p /mnt/userdata
        mount /dev/mmcblk0p4 /mnt/userdata
        ;;
  stop)
        echo -n "Stopping qttest..."
        ;;
  restart|reload)
        "$0" stop
        "$0" start
        ;;
  *)
        echo "Usage: $0 {start|stop|restart}"
        exit 1
esac

exit $?
```
结合厂商给的liunx平台用户手册关于触摸屏校准相关内容

上面时说：默认配置情况下，支持电容触摸。即烧写出厂的映像文件后，电容触摸屏直接可用。而且我们已经将电容屏的校正文件打包在文件系统中，开机无须再校屏了。这里我们主要讲解电阻触摸屏如何操作 UI 界面

那么这里的说的`“已经将电容屏的校正文件打包在文件系统中”`应该就是S99qttest中的`export TSLIB_CALIBFILE=/etc/pointercal`
（注：/etc下的 pointercal 文件是校准文件）

看来不能直接不执行S99qttest了

那就更改S99qttest文件内容，不执行/usr/share/demo/qttest -qws & 和 /usr/share/demo/hdmi_x210 &

复制一份S99qttest改名为oldS99qttest

S99qttest把 /usr/share/demo/qttest -qws & 和 /usr/share/demo/hdmi_x210 & 删除
（注：将来程序写好了再添加内容）

开机重新执行测试程序qt001

还是不行，明天再弄吧，为了不吵到舍友

明天试试吧测试程序放到S99qttest中，开机启动，如果还不行，那么就有可能是程序qt001本身的问题了(或者qttest做了什么事情)


---------------------------------------------------------------------------------

### 2016-12-23 udev规则 | ubuntu能识别DFK 22BUC03（未测试是否真的能用） 

把测试程序放到S99qttest触摸鼠标就正确了，不飘逸了。。。。那么我写一次程序岂不是要开机一次。。。。。。

开机后执行qttest,发现qttest下的触摸也不能正常工作，看来不是程序问题（那到底是什么原因呢？！！！！！）

问题一时半会也找不出答案，先进行下一步了：摄像头驱动

~ ~ ~ ~ ~ ~ ~ ~ ~ ~ 
把摄像头插进开发板。打印出信息：
[   78.225055] usb 1-1.4: new high speed USB device using s5p-ehci and address 3
[   78.655878] usb 1-1.4: New USB device found, idVendor=199e, idProduct=8202
[   78.661405] usb 1-1.4: New USB device strings: Mfr=2, Product=1, SerialNumber=3
[   78.668696] usb 1-1.4: Product: DFx 22BUC03
[   78.672807] usb 1-1.4: Manufacturer: The Imaging Source Europe GmbH
[   78.679058] usb 1-1.4: SerialNumber: 24314219

我的开发板/dev下永远有几个video的，不管有没有插入摄像头，所以没办法从是否有新的video设备文件来判断是否识别了uvc摄像头，但是从打印信息可以看出并没有识别到，正确的识别信息应该这种类型：
`............`

linux有uvc驱动,那么就应该能能发现摄像头，并创建相应的设备文件。问题到底出现在哪里呢？毫无头绪

~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~

安静思考一番：开发板DFK 22BUC03摄像头插进去之后是不能直接用的，那么先在ubuntu下搞，ubuntu下行得通的话，那么开发板也应该是类似的

在windows下安装好DFK 22BUC03摄像头的驱动，使PC能识别这个设备（windows驱动程序到映美精官网上下载）

打开ubuntu连接摄像头设备：虚拟机-->可移动设备-->Imaging Source Europe DFx 22BUC03-->连接（断开与主机的连接）

在我天真的以为/dev/下自然而然的出现video的时候，（DFK 22BUC03的设备描述就是TIS UVC device 而且在[http://www.ideasonboard.org/uvc](http://www.ideasonboard.org/uvc)

（一个网站，用来查看你的usb摄像头是否确实uvc摄像头，即是否能够被linux的UVC驱动识别）。确实有对应的设备ID，DFK 22BUC03的硬件ID为：199e:8202）

但是 没有！！！！

然后就开始一天的百度生活——什么linux uvc、开发板 uvc、ubuntu uvc....等，能想到的索引都搜了，该实验的也实验了，依然没什么收获

`！！！Manufacturer: The Imaging Source Europe GmbH！！！`

制造者是The Imaging Source

老师给的资料中有这么一步：`git clone https://githup.com/theimagingsource/tiscamera`
那么`https://githup.com/theimagingsource/tiscamera`应该是提供了相应的资料

（注：上面哪个地址访问不了。实际的地址是`https://github.com/TheImagingSource`）

~ ~ ~ ~ ~ ~ ~ ~ ~ ~ 20:43
从早上开始到现在，从一个毫无头绪到另外一个毫无头绪

想到好多切入点，结果都好乱，静下心来思考了一番：

已经是晚上8，9点了，突然想官网上提供的githup.com/theimagingsource/tiscamera，之前知道有这么一个东西，官网也说了是摄像头在linux系统上的驱动。但是进去看看了，一点都没有驱动的样子。

现在回过头来看，感觉谜底就在这里面了！！！

看源码看不出有什么东西了，看看issue有没有和我遇到一样的问题（好的，全部都是英文（T T）硬着头皮啃下来）

似有非有，然后发现了有说明书！！！在旁边的wiki......之前一直看源码下的README一直看不出个所以然。。。。。原来真正的家伙在这里

没错还是英文，说明书篇幅有点长，建立了一个word记录翻译

没错！在翻译的过程中我找到了为什么没有video设备文件了,以及如何解决
```
# UDEV Rules

Cameras like DMK41 already have a uvc mode but do not tell the operating system about this fact.
像DMK41的相机已经有一个uvc模式，但没告诉操作系统这个事实。

The udev rules are only required for USB2.0 CCD cameras.
udev规则仅适用于USB2.0 CCD摄像机。

Installing udev rules

To install the udev rules execute the following commands in :
要安装udev规则，请执行以下命令：

cd tiscamera
sudo cp data/udev/80-theimagingsource-cameras.rules /etc/udev/rules.d/
sudo service udev restart

Your system should now correctly identify your camera.
您的系统现在应正确识别您的相机。
```

`像DMK41的相机已经有一个uvc模式，但没告诉操作系统这个事实`，意思即摄像头连接到ubuntu也就是linux系统后，系统识别到usb设备，但是系统不知道这是一个USB Video device Class 。

从相应的githup地址`https://github.com/TheImagingSource/tiscamera`下载文件放进ubuntu并解压

不了解udev的可以先百度大概了解一下

进入tiscamera文件夹下

tiscamera/data/udev/80-theimagingsource-cameras.rules 这个文件就是使用udev规则来告诉系统我这个设备是一个Video类的设备

我们先看看这个文件的内容：cat data/udev/80-theimagingsource-cameras.rules
```
# This file assures that The Imaging Source USB cameras are correctly recognized
# This file only works for USB2 cameras whose name ends with a 1 (e.g. DMK 31, DFK41, etc.)

# if no driver has claimed the interface yet, load uvcvideo
ACTION=="add", SUBSYSTEM=="usb", \
ATTRS{idVendor}=="199e", ATTRS{idProduct}=="8101", \
RUN+="/sbin/modprobe -b uvcvideo"

# add the imaging source VID and PID to the list of devices supported by uvcvideo
ACTION=="add", SUBSYSTEM=="drivers", \
               ENV{DEVPATH}=="/bus/usb/drivers/uvcvideo", \
               ATTR{new_id}="199e 8101"

```
我们DFK 22BUC03 的硬件id是：`199e:8202`；进行相应的修改

按照要求拷贝到/etc/udev/rules.d/下

重新启动ubuntu（重新启动udev并不行）

根据说明设置之后，在/dev/下已经能够看到video0这个设备文件了
执行dmesg命令

    [ 1446.647213] usb 1-1: new high-speed USB device number 3 using ehci-pci
    [ 1446.951243] usb 1-1: New USB device found, idVendor=199e, idProduct=8202
    [ 1446.951261] usb 1-1: New USB device strings: Mfr=2, Product=1, SerialNumber=3
    [ 1446.951265] usb 1-1: Product: DFx 22BUC03
    [ 1446.951267] usb 1-1: Manufacturer: The Imaging Source Europe GmbH
    [ 1446.951269] usb 1-1: SerialNumber: 24314219
    [ 1447.277947] Linux video capture interface: v2.00
    [ 1447.391255] usbcore: registered new interface driver uvcvideo
    [ 1447.391258] USB Video Class driver (1.1.1)
    [ 1447.391649] uvcvideo: Found UVC 1.00 device DFx 22BUC03 (199e:8202)
    [ 1447.853778] input: DFx 22BUC03 as /devices/pci0000:00/0000:00:11.0/0000:02:03.0/usb1/1-1/1-1:1.0/input/input5
    [ 1695.997348] uvcvideo: Failed to query (GET_DEF) UVC control 4 on unit 3: -110 (exp. 2).

但是执行cheese程序发现还是不能直接用，但是错误已经不是no fund device 了。可能是cheese这个软件原因也可能是其他原因

反正能看到video0已经是一个很大的进展了！！！明天继续（写完这些笔记已经是1：43了）

~ ~ ~ ~ ~ ~ ~ ~ ~ ~  凌晨1：43  

--------------------------------------------------------------------------
### 2016-12-24 mdev规则 | 使开发板能识别DFK 22BUC03（未测试是否真的能用）

今天是圣诞节呢，圣诞快乐，天气有点冷

昨天在ubuntu下通过udev规则使能出现设备节点/dev/video0

今天就尝试下开发板下，依然是有问题的

首先。开发板没有udev!!! 但开发板的内核版本是2.26.35 是有uvc驱动的

开发板有mdev

百度mdev和udev 。。。。。

百度mdev 使用规则。。。。。。

不知道原理不知道怎么搞啊！！！！！

快崩溃了！！！！真的是绝望！！！！

自己移植系统？？？！！！难度好像有点大，而且现在也没有那么多时间

哎呀，怎么九鼎提供的linux+QT的系统镜像版本那么低，内核配置选项也没有udev相关选项；只能使用mdev,可是mdev又不懂，真的是不知道怎么办

~ ~ ~ ~  ~  ~ ~ ~ ~ ~ 19：27
**再去官方的githup查看issue，有一个好像也挺类似我的，试试看没想到有一点现象了！**
控制台下输入`echo "199e 8202" | sudo tee /sys/bus/usb/drivers/uvcvideo/new_id`

[ 1585.750490] uvcvideo: Found UVC 1.00 device DFx 22BUC03 (199e:8202)
[ 1586.642533] input: DFx 22BUC03 as /devices/platform/s5p-ehci/usb1/1-1/1-1.3/1-1.3:1.0/input/input5

连接地址：https://github.com/TheImagingSource/tiscamera/issues/5

接下来抱着怀疑的态度写测试程序（基于v4l2）

暂时没那么快能写出来，还要熟悉v4l2

~ ~ ~ ~  ~  ~ ~ ~ ~ ~ 21:10
昨天不是可以在ubuntu下看到设备文件吗，下载了一个luvcview，执行，没能正确显示图像（一片绿）
打印信息：
```
view 0.2.6

SDL information:
 Video driver: x11
 A window manager is available
Device information:
 Device path:  /dev/video0
Stream settings:
 Frame format: YUYV (MJPG is not supported by device)
 Frame size:   372x480 (requested size 640x480 is not supported by device)
 Frame rate:   30 fps
```

------------------------------------------------------------------
### 2016-12-25 

天气不错，早起去食堂吃了个饭，清晨的空气很好

跟老师确认了一下，是CCD摄像头，根据TIS的说明是不用升级固件，只要告诉驱动是uvc设备就OK。和之前的方式一样，但是重启之后就失效了，后面需要处理一下是否能写进开机程序中

> 之前不是说了我的开发板比较奇葩吗，无论是否有插进摄像头，都有那么几个video0。要完全理解还要从uvc驱动源码入手。结合之前学过的驱动知识

首先明白/dev下的设备文件是怎么来的，`class_create`和`create_device`...(注：在一开始学驱动的时候，没介绍`class_create`和`create_device`我们是通过mknod命令来创建设备节点)。创建设备节点需要主次设备号，设备号从哪里来？——`lsmod`;x想知道已经存在的设备文件的主次设备号——`ls -al`好像。我们通过`lsmod`和`ls`可以看到video*设备文件的主设备号和系统给uvc驱动的字符设备号是一样的，都是81

### 2016-12-30

给专业课程设计占了好多时间，还得继续一周。特别是舵机特难调。今天腾出些时间继续！

### 2017-1-1

新的一年快乐！

### 2017-1-2

熟悉了v4l2的流程，结合之前学过的LCD相关操作，copy [Kevin_Mr的代码](http://blog.csdn.net/kevin_mr/article/details/51470215)，显示是显示了但是花屏。。。。

可能出错原因
    1. 采集的yuv是错误的
    2. yuyv转RGB32错误(改成另外一个`yuv_to_rgb`转换程序也还是不行)
    3. 帧速率问题(因为看到花屏后移动摄像头也没多大变换，所以猜想很大的可能是源头出问题)
明天又要开始课设了，有时间把程序中的显示改成保存成文件.yuv，再用pyuv看能不能打开

### 2017-1-6

两周的机械电子课程设计终于结束了，课设内容很多，以小组配合的形式完成，自己负责的是程序的部分

两周的课设在充实的每一天下转瞬即逝。收获颇丰，熟悉了机电产品设计的大致流程，整合所学知识，理论知识能够转化为实际运用。

在小组的主要任务是小车和机械手程序的设计，采用8951的MCU，是比较久远的一款芯片了。引脚功能较少，无疑给软件设计增加了难度，但因此我们也提升了逻辑思维的能力，充分利用编程语言灵活的特性，实现相应的功能，进一步丰富程序设计的经验。虽然说设计不难，但是还有很多细节，比如如何软件模拟PWM

另外外围电路也要自己设计，包括引脚功能要怎么定义，然后以此来设计PCB，并制作出来。传感器的电路也要自己设计，总之是一次非常好的经验。比较遗憾的是，课程还涉及到机械部分，由其他成员来完成，再结束之际了解了一下，他们的工具量完全不亚于程序的设计，比如电机的选型，轴的选择，轴承导轨滚珠丝杠手爪蜗轮蜗杆连杆等等，根据载荷受力情况抗弯抗矩寿命疲劳强度速度加速度等等，一堆计算，是对三年的学习的机械和电机的知识一次较详细的综合，没有时间参与挺可惜的。虽然以后想从事的方向不是机械方向，但还是希望能多了解一点。

课设小组配合，大家相互交流，分配合作，比起自己一个人处理事情愉悦了许多。出了难题大家可以一起想办法解决，为着同一个目标一起努力。感受到了团队合作的力量，大家乐此不疲，氛围很好，恰逢毕业时许，想到即将与大家分开竟然有些难过。希望以后步入工作也有一群开朗的同事，也希望成为别人那个乐观积极的同事。

### 2017-1-7

继续之前的`s5pv210 usb摄像头 v4l2 uvc驱动`的内容，上次的花屏问题已经解决了，原因是参考的那个程序没有对摄像头进行相应的设置，主要设置如下：
```
    .....
    fmt.fmt.pix.width  = 640;  //图片宽度
    fmt.fmt.pix.height = 480;  //图片高度 
	fmt.fmt.pix.pixelformat = V4L2_PIX_FMT_YUYV;
	fmt.fmt.pix.field  = V4L2_FIELD_INTERLACED;//隔行扫描 显示必须也是隔行扫描
	
	if(-1 == ioctl(cam_fd, VIDIOC_S_FMT, &fmt)){//设置图片格式  
        perror("set format failed!");  
        goto ERROR;  
    }
    ......
```

### 2017-1-8

很多东西都只是看懂了，然后用了起来实现相应功能，将来写论文时再慢慢整理吧

bmp图片的显示和采集有了一丁点进展，主要是有网上认识的一个西安大四同学王凯的帮忙

但是还是有些问题，只能正确采集到第一张，采集后面的，是一半一半显示的

![采集的第一帧图像](https://raw.githubusercontent.com/TongxinV/Video-Image-Processing/master/assets/P002.png)![采集的第五帧图像](https://raw.githubusercontent.com/TongxinV/Video-Image-Processing/master/assets/P004.png)



仔细看了看程序，虽然有bmp图片的处理，但是显示实际还是用RGB32显示（程序实际是直接把RGB32的数据存到一张bmp图片，然后把bmp图片的RGB数据拿出来再显示到LCD，晕），得到的bmp图片不能在PC上显示，提示伪文件头数据`BMP image has bogus header data` 还是得找些bmp相关的资料看看。



从采集到的图片大小也可以看出不正常：
正常的一张同样大小的640*480图片，大小为： 921654（多出的这54应该就是头文件数据）
采集到的第一帧图片的大小为： 921600
采集到的第五帧图片的大小为：4608000



### 2017-1-11

又开始了两周的实习，实习过后再过一个月就是春招了，还有好多东西需要学习希望能找到一个好的发展平台，所以打算腾出一个月来整理。

基于嵌入式视觉图像处理的课题就暂时放下了，今天和老师汇报了一下进度，整理下以后需要解决的问题：
**bmp图像文件的存取** **C++语言的复习和运用** **opencv能否整合到程序中**

2016-1-11 20：22 记————李炎彬


### 2017-02-17 10:56

好快...不知不觉就开学了，老师说我项目得赶紧做。。。。。

该项目主要还是在应用层上的实现，之前基于v4l2的摄像头采集程序是用C语言实现的，也曾用C语言写过一个简单的应用程序。现在不想用C语言编写应用程序了，第一：想重新复习下C++，一直在学习嵌入式驱动开发，C语言接触得比较多，也一直在用C语言，偶尔换换口味还是很有必要的；第二：个人理解随着嵌入式CPU性能的提高已经能够使C++开发的一些大型程序在开发板上能够流畅运行，而且应用程序方面使用C++也是比较主流的一种做法；第三：很多库支持C++接口更加丰富，如将来需要使用的opencv库，它的一些新特性都是C++ 接口。


网上搜索了嵌入式纯C++应用开发，很少，大部分是qt。开发项目的功能实现是可以不用GUI的，不想程序那么笨重。qt/Embedded是通过QtAPI与Linux I/O以及Framebuffer直接交互，即它要能够显示或者触摸功能显示肯定要跟设备文件打交道，那我参考它这些功能实现就OK了，那就要去参考看源码咯，qt源码好像没找到，也没认真找。之前看过韦东山编著的《嵌入式Linux应用开发完全手册》中的第25章对嵌入式Linux中的几种GUI的介绍，了解到qte。在githup上找到了源码(8年前的源码...)，这个代码量比较少，应该比较好理解。通过关键字搜索它对显示这一块的封装，结果和之前的猜测一样，和之前用C语言实现的方式一样，只不过用C++来写罢了。


解决了心中的疑惑的，下一步就是重新拾起C++了:muscle:

偶然想起家里的路由器，也是没有界面的，设置的时候是通过网页来实现的，这种设计思路是什么呢？要自己能够开发还需要掌握哪些知识呢？:confused:想了解



### 2017-02-27 08:50

没有找到工作，得为找工作做准备，好多东西得复习，还要看算法。一直静不下心来搞项目，挤出宝贵的时间花几天把C++仔仔细细回顾了一下，看的是浙江大学翁恺老师的公开课《面对对象编程-C++》，适合有一定基础的同学，不过也还是基础，实际还是需要结合一些书或网上来加深理解。当然学习和编程又是另外一回事了，昨天开始的项目编程，关于show video的功能之前已经用C语言实现了，触摸功能在Image Player项目中也接触过，所以大概个流程已经有个底了。接下来就是编程的事了


之前打算用QT来做这个项目的，老师说需要实现按键功能，即用qt的gui来实现，所以有移植好QT库和ubuntu下安装好qtcreator，交叉编译工具也配好了，可以用起来。但个人不太喜欢QT那么臃肿，而且QT只是为了实现一个按键功能，项目的重点是利用opencv进行图像处理，个人也比较熟悉linux所以就没再用QT了，改为纯C++项目。但qtcreator这个IDE还是可以的，它的机制是利用自己的qmake工具生成Makefile，有可以省下写Makefile的时间了（这不是偷懒:laughing:）。

尝试了复杂一点的程序，下载到开发板，可以正常运行。

另外说一点，C++编程还是有难度的，程序的架构怎么设计对于我这个新手真的是难，平行关系的对象如何进行数据交流又是一个问题，还不说要考虑构造析构继承重载等等等等等一系列问题。不过这个真的是能很大提高能力，赶快找到工作，好好研究研究（这句话的意思是项目又要延期了。。。。。）


### 2017-02-28 12:21

忍不住又做起起项目来(嗯，只搞一小会)，今天发现了qtcreator一个**major issues**，似乎不支持多文件夹编译：main.cpp用
    
    #include <xxx.h>提示没有xxx.h文件
    
不会要把所有文件都放在一个跟目录下吧！:scream:接收不了。。。:triumph:，可有没有编写过C++工程的Makefile的经验，不知道会不会出现什么莫名其妙的问题。网上找了下资料，有网友似乎有类似的问题：[《qt下的跨目录多工程编译》](qt下的跨目录多工程编译)，看了一下，结合以前学过的Makefile相关知识，在根目录下的pro添加 `INCLUDEPATH += ./include `。OK


### 2017-03-02 12:25


工程重新构建（跨目录多工程编译）：应用程序和源代码分开，源代码静态编译成库放到lib目录下

今天犯了一个错误，写了一天的源代码被我rm删除了，新建的工程后忘记把旧工程的代码拷贝过来，感觉要升天。还好只是一天，不过也是一次深刻的体会了，以后rm一定好考虑好。


### 2017-03-10 

今天去星网锐捷面试啦，昨天跑到厦大去笔试，来的人还挺多的。软件研发只招10个人。压力好大:astonished:。很幸运的得到了面试的机会，哇，学了一年的东西全部搬上简历，让我复习得感觉要升天:angel:。其实之前已经复习了很久，还看了数据结构和一些简单算法，但感觉怎么复习还是不能够游刃有余，还是不够优秀啊:muscle:

技术面，问了驱动，图片项目和我现在在做的项目，我还跟他提了一些简历上没有的项目，主要是一些利用51单片做的项目，我感觉不是太难，所以没写在简历上，不过51单片机项目也很大提升我的编程能力，然后再问了uboot移植。感觉自己还是嘴笨，嘴巴跟不上大脑的思维。整个面试还是很紧张，有些能够突出自己能力的细节在表达的时候不能够加上去（面试回来的反思）。

然后是HR面，HR简单问了我的学习情况家庭情况。我跟他表明自己一直在利用课余时间坚持不断的学习嵌入式知识，还有在很早之前就为以后的工作做准备（想想，再过一个半月自己默默学习嵌入式就一年了，一有时间就学习，很充实，自己能坚持这么久主要原因是兴趣，其中不乏有过落寞，好了还是不伤感了，不经一番彻骨寒，怎得梅花扑鼻香）。

然后回去等通知，大约九点的时候，星网锐捷就给我打电话了，效率好高:thumbsup:。恭喜我成功被录取了:sob:

这么久的努力终于有回报了:sob:

未来的路很长，做自己喜欢的事并给自己下目标（多次思考人生的总结!）。我的一生一定会很精彩的，此生注定不安逸，祝福自己:heart:

不对啊。。。还要去其他投简历吗？星网锐捷好像已经很好了对我来说。。。春招第一次就面试成功，自己都没想到。。。看看把，先把项目赶紧做出来，不然要狗带了。


### 2017-03-11 13:11


时间过得好快，再次梳理代码。C++好难，难在架构的设计，如何设计让我思考很久，接口如何设计，如何数据交流等等。**I need an architect **

好在马马虎虎设计了出来：

    LinuxFbScreen
        C1Screen
        C1Painter
        C1Image

测试了刷屏幕背景，succeed！

### 2017-03-12 13:20

> **坚持OOP原则**

写C++还是需要大量的经验的积累。在写程序的时候，由于对数据的保护，一个对象要访问另外一个对象的私有数据就需要调用相应的接口。在设计这样的接口我能想到的就是值的拷贝，那么这样效率不是很低吗？设计成友元函数又破坏了OOP原则。不知道有什么好的方式。我想的另外一种方式是**求公约数**。比如painter和image类，画图painter需要`宽、高和数据指针`，图像image有`宽、高和数据指针`，然后把`宽、高和数据指针`提取出来设计成一个新的类。然后painter和image类去包含，但是细想了一下，其实本质还是一样，并不能提高效率。而且架构越设计越复杂。

另外，对于类的嵌套有两种方式：继承和组合

还有就是在对析构不够了解的情况，一定要使用引用。因为进行值传递的时候，如果没有自己定义的拷贝构造函数，在析构的时候会发生错误。


最终还是把图片显示的程序写出来了（图片image和显示屏screen分开）：

    main
        img
        screen
        
测试结果：

![](https://raw.githubusercontent.com/TongxinV/Video-Image-Processing/master/doc/assets/P001cc.png)



### 2017-03-13 21:25

终于完成图片文件读取部分，层次的设计接口的设计难，要想写合适确实要思考很久。想设计一个返回指针的函数折腾半天，还有使用到malloc，还需要考虑free的问题。
    main
        ├── img->loadFromData
        ├── screen->setPixmap
        ├── img->freeData
        └── ...
    
    
### 2017-03-14 22:16

完成摄像头设备的读取以及关于v4l2的设置，还好之前有接触过，不然一天相信是搞不完了。另外纪念一下第一次遇到C++下的内存错误：corrupt double-linked list：0x00012658.(通过把函数一个个注释掉，找到发生错误的函数，然后分析)

另外重新认识了V4L2采集原理：造盘子+造传送带


### 2017-03-15 13:56

完成视频的读取和显示到屏幕上，终于写好了，其实前面架构的设计想好了，后面会写得很快，采集到的一帧图像：

![](https://raw.githubusercontent.com/TongxinV/Video-Image-Processing/master/doc/assets/P002cc.png)



一些打印信息：

```c
-sh-4.2# ./app 
1.
1.
/dev/fb0.
smem_start = 0x475ab000, smem_len = 4915200.
xres = 1024, yres = 600.
xres_virtual = 1024, yres_virtual = 1200.
bpp = 32.
fb mmap success. pfb = 0x40fe7000.
Capability infrmations: 
driver: uvcvideo
card: USB Camera
bus_info:usb-s5pv210-1.4
version:00000100
capabilities:04000001
fmt.type:               1
pix.pixelformat:        YUYV
pix.width:              640
pix.height:             480
pix.field:              1
request buffer success.
Frame buffer 4: address = 0x41497000, length = 614400 
Frame buffer 4: address = 0x4152d000, length = 614400 
Frame buffer 4: address = 0x415c3000, length = 614400 
Frame buffer 4: address = 0x41659000, length = 614400 
 start video capture success.
Hello World!
 stop video capture success.
```


另外改进了任意位置显示图片的算法：

```cc
void C1Painter::_setPixmap(unsigned int x, unsigned int y, const C1Image *img)
{
    if(!img){
        printf("Images isn't exit!.\n");
        return ;
    }

    unsigned int *p = pStar + y * Width + x;        //画笔位置

    const unsigned char * Byte =img->data ();
    unsigned int imageWidth    =img->width();
    unsigned int imageHeight   =img->height();

    unsigned int i,j;
    unsigned int cnt;

    for (i = 0; (i<imageHeight)&&(i<Height-y); ++i)
    {
        for (j = 0; (j<imageWidth)&&(j<Width-x); ++j)
        {
            cnt = imageWidth*i+j;
            cnt*=3;
            *(p + i * Width + j) = ((Byte[cnt+0] << 16) | (Byte[cnt+1] << 8) | (Byte[cnt+2] << 0));//byte[0-2]:R G B
        }
    }

}


```

### 2017-03-17 19:23

改下yuyv转rgb的算法，把浮点运算替换成整型，流畅性有那么一点点的改善（gif图片有点大加载前会卡，而不是我的视频卡！！！请注意让它先加载完~）


![](https://raw.githubusercontent.com/TongxinV/Video-Image-Processing/master/doc/assets/P003cc.gif)



### 2017-03-20 20:25

这两天移植了opencv库后使用时遇到点问题：

**问题一**：添加opencv头文件和动态链接库

尝试修改xxx.pro：虽然可以正确使用，但是格式太恶心了：
```
INCLUDEPATH += ../../../../../../../lib-opencv/include 

LIBS += -L ../../../../../../../lib-opencv/lib -lopencv_core

```

在xxx.pro文件中直接添加：
```
INCLUDEPATH += /opt/lib-opencv/include
DEPENDPATH  += /opt/lib-opencv/include

LIBS += -L/opt/lib-opencv/lib/ -lopencv_core
```
是不行的

所以直接去修改Makefile文件：
```
...
INCPATH       = -I/... -I/opt/lib-opencv/include 

...
LIBS          = $(SUBLIBS)  -L/... -L/opt/lib-opencv/lib -lopencv_core -lQtCore -lpthread

```


**问题二**：编译好的文件放到开发板下后不能找到链接库

打印的错误信息：
```
 error while loading shared libraries: ../../lib/libcxcore.so: cannot open shared object file: No such file or directory
```
解决该错误需要解决两点：

**1**.`../../lib/`下找.so说明运行目录不能在第三级子目录以上，或者运行目录的`../../`下有lib目录，而且里面放着要用的.so，运行目录在前两级目录中，这个程序就会去/lib下去找.so

解决办法：直接把可执行文件放到根目录下


**2**.放到根目录下还是提示找不到动态库，我是把相关库文件放在了``/usr/lib`下，但是不行

解决办法：把库文件放到`/lib`下，可以但是想一想如果每次都放到这个目录下，显然不合理。所以我根据以前的知识，把库文件放到随意一个目录，也不能太随意，通常放到`opt`目录下，我的路径是`opt/lib-opencv`。然后用expor临时导出
```
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/lib-opencv/lib
```
注：这个是临时性的，重新开机的时候，这个就得重新设置，可以在`~/.bash_profile`中添加或`/etc/profile`


### 2017-03-21 20:25

昨天解决了编译链接库的问题,因为图像显示和视频采集都是自己设计的，没有使用QT或opencv的框架

使用opencv首先要把图像数据转成Mat类型的对象，一开始还尝试思量着要把rgb弄成bmp，然后用imread接口

但是思考一番还是不是太像这样做，这里直接说怎么做的把，利用构造函数，示例如下：

```
    uchar matrix[90] = {

        0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,
        0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,
        0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,
        0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,
        0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,
        0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff,0xff

    };
    //将位图数据直接转成Mat类型对象
    //Mat img(1024, 600, CV_8UC3, (char *)Image_001);
    Mat img(5, 6, CV_8UC3, (char *)matrix);

    cout << img;

```

是能正确打印的，但不知道后面是否能正常处理。（另外这要处理不知道是另外复制了一份数据还是用指针引用，暂时不考虑这个问题）


Mat对象处理后要显示出来，那么就需要把Mat类型的对象的图像数据提取出来：

参考了这篇博客[《OpenCV笔记（二）——查看Mat对象的数据的三种方法》](http://www.tuicool.com/articles/Q7fmeqM)

还有这篇博客[《Opencv 中 Mat中元素的值读取方法总结》](http://lib.csdn.net/article/opencv/33144)



### 2017-03-22 16:01

折腾了一会，把Mat对象的图像数据打印出来，用16进制类型(%x)打印类型，或用int类型(%d)打印都可以。

```
    //利用工具把一幅图片转成只包含数据的数组，数组名IM_320_240
    
    //将位图数据直接转成Mat类型对象
    Mat imageSource(320, 240, CV_8UC3, (uchar *)IM_320_240);

    //打印部分数据看是否正确
    for(int i = 0; i < 10; ++i){
        printf("imageSource.ptr<uchar>(0)[0] = %x.\n", imageSource.ptr<uchar>(0)[i]);
    }
    
    
```

直接把Mat中的data指针拿来使用去显示会报段错误，原因竟然是一个循环i写成j。。。。。只要`isContinous`为true,就可以直接这样处理

```
    Mat imageSource(240, 320, CV_8UC3, (uchar *)IM_320_240);//将位图数据直接转成Mat类型对象

    uchar* data = imageSource.data;

    //图片显示测试
    LinuxFbScreen screen(1024, 600);
    screen.initDevice();

    //screen.showImageData(320, 240, (unsigned char *)IM_320_240);

    screen.showImageData(320, 240, data);

    //img->freeData();

    sleep(3);
    screen.shutdownDevice();


```


注：如果要把图像显示出来要把char组合成一个int类型的，原因不再赘述

```
```

BGR图片转成灰度图后，灰度图是单通道的，怎么显示又是一个问题，有点晚了，明天再弄

### 2017-03-23 20:59

灰度图的显示就是把rgb三通道的值设置为灰度图单通道的值，即r=g=b

**彩色图转灰度图算法**：

参考博客：[《C++ RGB转灰度图像》]()

```cc
//******************灰度转换函数*************************
//第一个参数image输入的彩色RGB图像；
//第二个参数imageGray是转换后输出的灰度图像；
//*******************************************************
void ConvertRGB2GRAY(const Mat &image,Mat &imageGray)
{
    if(!image.data||image.channels()!=3)
    {
        return ;
    }
    imageGray=Mat::zeros(image.size(),CV_8UC1);
    uchar *pointImage=image.data;
    uchar *pointImageGray=imageGray.data;
    int stepImage=image.step;
    int stepImageGray=imageGray.step;

    int i,j;
    int cnt;

    for(i=0;i<imageGray.rows;i++)
    {
        for(j=0;j<imageGray.cols;j++)
        {
            //pointImageGray[i*stepImageGray+j]=0.114*pointImage[i*stepImage+3*j]+0.587*pointImage[i*stepImage+3*j+1]+0.299*pointImage[i*stepImage+3*j+2];
            cnt = i*stepImage+3*j;
            pointImageGray[i*stepImageGray+j]=(76*pointImage[cnt+0]+150*pointImage[cnt+1]+30*pointImage[cnt+2]) >> 8;
        }
    }
}

```


直接调用canny接口：

关于canny接口参考这篇文章：

```cc
#include <iostream>
#include <unistd.h>

#include <smdkv210/linuxfbscreen.h>
#include "IM_320_240.h"

#include "opencv2/core.hpp"
#include "opencv2/imgproc/imgproc.hpp"

using namespace std;
using namespace cv;

void ConvertRGB2GRAY(const Mat &image,Mat &imageGray);

Mat imageSource;
Mat imageGray;
Mat imageCanny;

int main()
{
    LinuxFbScreen screen(1024, 600);
    screen.initDevice();

    //============================

    Mat imageSource(240, 320, CV_8UC3, (uchar *)IM_320_240);//将位图数据直接转成Mat类型对象

    uchar* data = NULL;

    data = imageSource.data; //提取处理后的Mat类型对象的像素数据
    screen.showImageBGR(320, 240, data);

    ConvertRGB2GRAY(imageSource,imageGray); //RGB转换为灰度图

    data = imageGray.data;   //提取处理后的Mat类型对象的像素数据
    screen.showImageGray(320, 240, data);

    Canny(imageGray, imageCanny, 100, 300, 3);//边缘检测

    data = imageCanny.data;  //提取处理后的Mat类型对象的像素数据
    screen.showImageGray(320, 240, data);

    //=============================

    sleep(3);
    screen.shutdownDevice();

    cout << "Hello World!" << endl;
    return 0;
}



//******************灰度转换函数*************************
//第一个参数image输入的彩色RGB图像；
//第二个参数imageGray是转换后输出的灰度图像；
//*****************************************************
void ConvertRGB2GRAY(const Mat &image,Mat &imageGray)
{
    if(!image.data||image.channels()!=3)
    {
        return ;
    }
    imageGray=Mat::zeros(image.size(),CV_8UC1);
    uchar *pointImage=image.data;
    uchar *pointImageGray=imageGray.data;
    int stepImage=image.step;
    int stepImageGray=imageGray.step;

    int i,j;
    int cnt;

    for(i=0;i<imageGray.rows;i++)
    {
        for(j=0;j<imageGray.cols;j++)
        {
            //pointImageGray[i*stepImageGray+j]=0.114*pointImage[i*stepImage+3*j]+0.587*pointImage[i*stepImage+3*j+1]+0.299*pointImage[i*stepImage+3*j+2];
            cnt = i*stepImage+3*j;
            pointImageGray[i*stepImageGray+j]=(76*pointImage[cnt+0]+150*pointImage[cnt+1]+30*pointImage[cnt+2]) >> 8;
        }
    }
}



```

**处理图像结果**

![](https://raw.githubusercontent.com/TongxinV/Video-Image-Processing/master/doc/assets/opencv%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%BB%93%E6%9E%9C.png)




### 2017-03-25 11:03

* 实现对采集到的图片进行边缘检测

* 添加触摸事件（多线程实现）

* 解决一些BUG：mmap没有munmap导致驱动程序出错（比如结束的时候视频申请的帧缓冲没释放）

2017-03-25 21:47:51

上面提到的驱动程序导致错误，不是munmap导致的(不过也帮忙完善了程序)，改了之后程序运行到边缘检测函数，V4L2驱动就会报错

```
uvcvideo: Failed to resubmit video URB (-19).
[  500.967493] uvcvideo: Failed to resubmit video URB (-19).
[  500.972863] uvcvideo: Failed to resubmit video URB (-19).
[  500.978234] uvcvideo: Failed to resubmit video URB (-19).
[  500.983606] uvcvideo: Failed to resubmit video URB (-19).

```

貌似解决不了，但还是要硬着头皮去搞

**猜测1**：Mat类对象中的数据指针指向的内存是外部申请好的，即其内部并没有另外开辟内存空间。在Mat类对象调用结束去析构时，会释放`Mat类对象中的数据指针指向的内存`

实验结果：还是会触发V4L2驱动相关的错误，但是发现了，只要不掉用Canny函数就正常，先到这里明天再看看（2017-03-26 00:01:00）

### 2017-03-26 09:55

早上测试了一下，发现不去显示图片时不会报错，也就是不是Canny的错误

URB : usb request block，Linux内核中USB驱动实现上的一个数据结构，用于组织每一次的USB设备驱动的数据传输请求

`Failed to resubmit video URB`：未能提交video的 URB

能力有限，暂时不解决了，只能先把显示处理后的图像那一步注释掉，进行下一步，运动控制


如果没有UVC驱动问题的话是可以像下面展示的效果，触摸控制是进行视频显示还是进行图像处理，用线程实现触摸事件的获取：

![](https://raw.githubusercontent.com/TongxinV/Video-Image-Processing/master/doc/assets/P111cc.gif)


**working...**

看了底板原理图，九鼎的开发板也就是我现在在用的s5pv210，没有引出PWM引脚。

另辟蹊径，看了九鼎引出的也就是可扩展的引脚的功能有串口，那么我就在想：开发板这边用写一个串口驱动(不是用控制台的串口)对外发送控制消息，电机那边用STM32控制，STM32接收开发板串口发送过来的消息。

主要是对串口驱动不熟悉，而且写驱动的能力也只能算是新手，有点难。。。。

跟老师沟通了下，先写论文，时间足够的话，再来搞这一块。


截至目前，主要功能实现：

* framebuffer设置/显示图像
* 利用V4L2进行视频数据提取/视频数据转换/实时显示
* 移植opencv/使用opencv进行图像处理
* 多线程实现触摸控制


### 忘记更新了，补充


最终的效果为提取物体轮廓的重心，效果图如下：

![](https://raw.githubusercontent.com/TongxinV/Video-Image-Processing/master/doc/assets/R001.png)


其实在硬件平台和软件平台构建起来之后（软件平台包括操作系统和OpenCV移植，另外你还需要了解一些makefile如何添加动态库路径），最可以在上层应用进行相关的图像处理程序的编写。上层应用实现部分代码如下：

```c

   /* 
	* 轮廓中心坐标计算实现代码
    */
	imageSource = Mat(480, 640, CV_8UC3, sv.data()).clone();//用数据初始化矩阵变量

	ConvertRGB2GRAY(imageSource,imageGray);                   //RGB转换为灰度图

	GaussianBlur(imageGray, imageGray, size(3, 3), 0, 0);     //高斯滤波平滑图像

	Canny(imageGray, imageCanny, 50, 150, 3);                 //边缘检测处理

	//在得到的二值图像中寻找轮廓
	vector< vector<Point> > contours;
	vector< Vec4i > hierarchy;
	findContours(imageCanny, contours, hierarchy, RETR_EXTERNAL, CHAIN_APPROX_NONE, Point(0, 0));

	//在原有图像上绘制轮廓
	for(int i = 0; i < (int)contours.size(); i++)
	{
		drawContours(imageCanny, contours, i, Scalar(255), 1, 8);
	}

	//计算轮廓的矩
	vector<Moments> g_vMoments(contours.size());
	for(int i = 0; i < (int)contours.size(); i++)
	{
		g_vMoments[i] = moments(contours[i], true);
	}

	//利用计算得到的矩计算中心矩
	vector<Point2f> centerMoments(contours.size());
	for(int i = 0; i < (int)contours.size(); i++)
	{
		centerMoments[i] = Point2i(float(g_vMoments[i].m10 / g_vMoments[i].m00), float(g_vMoments[i].m01 / g_vMoments[i].m00));
	}
	//输出所有轮廓的中心矩
	for(int i = 0; i < (int)contours.size(); i++)
	{
		cout <<"【用矩计算出来的第" <<i<<"个轮廓的中心为：】" << centerMoments[i].x << "," << centerMoments[i].y << endl;
	}

	//将得到的中心矩在图中画出
	for(int i = 0; i < (int)contours.size(); i++)
	{
		circle(imageCanny, (Point2f)centerMoments[i], 5, Scalar(255), -1, 8);
	}

	sv.showImagesGray(imageCanny.data);



```

























